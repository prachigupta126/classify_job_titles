{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import sklearn\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import pandas as pd\n",
    "import  xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Changing the path of data\n",
    "import os \n",
    "os.chdir('C:/Uconn MSBA/studies/Kaggle/data and code/TMP_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating usable Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(filePath='job-classifications.txt'):\n",
    "    \"\"\"\n",
    "    Function will load the data from the given path into a dataframe\n",
    "    \n",
    "    Arguments:\n",
    "    filePath -- path of the file \n",
    "    \n",
    "    Return:\n",
    "    data --  dataframe \n",
    "            \n",
    "    \"\"\"\n",
    "    data = pd.read_table(filePath, index_col=None, engine='python')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcessing(features):\n",
    "       \n",
    "    \"\"\"\n",
    "    Function will preprocess the titles \n",
    "    \n",
    "    Arguments:\n",
    "    features -- Series of string \n",
    "    \n",
    "    Return:\n",
    "    clean_titles -- Series of string titles\n",
    "    clean_wordlist -- Series of list of titles\n",
    "        \n",
    "    \"\"\"\n",
    "    num_titles = features.size\n",
    "    clean_wordlist = []\n",
    "    clean_titles = []\n",
    "    \n",
    "    # Extracting unique stopwords from English language \n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    for i in range( 0, num_titles):\n",
    "        #letters_only = re.sub(\"[^a-zA-Z]\", \" \", features[i]) \n",
    "        \n",
    "        words = str(features[i]).lower().split()\n",
    "        \n",
    "        # Converting words into lower case for symmetry \n",
    "        words = [w.lower() for w in words if not w in stops]  \n",
    "        \n",
    "        # Appending preprocessed words in a list \n",
    "        clean_wordlist.append(words)\n",
    "        \n",
    "        # Converting list to string \n",
    "        clean_titles.append(\" \".join(words))\n",
    "    return clean_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_modification(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function will do basicn EDA on the data \n",
    "    \n",
    "    Arguments:\n",
    "    data -- dataframe\n",
    "    \n",
    "    Return:\n",
    "    data -- Preprocessed dataframe\n",
    "            \n",
    "    \"\"\"\n",
    "  \n",
    "    # rename a column to remove space\n",
    "    data = data.rename(columns={'Job Title': 'Job_Title'})\n",
    "    \n",
    "    # drop missing values as they are very few\n",
    "    data = data.dropna(how='any',axis=0)\n",
    "    \n",
    "    # Reset index\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function will Split the data in train and validation set\n",
    "    \n",
    "    Arguments:\n",
    "    data -- dataframe\n",
    "\n",
    "    Return:\n",
    "    train_x,valid_x,train_y,valid_y -- traning and validation set\n",
    "            \n",
    "    \"\"\"\n",
    "        \n",
    "    y = data['Category']\n",
    "    X = data[['Job_Title','Class']]\n",
    "    \n",
    "    # stratified sampling as this is imbalanced dataset\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.5,stratify=y)\n",
    "    return train_x,valid_x,train_y,valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "def create_countvector(train_x,valid_x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function will calculate frequency of every term(column) in every document(row)\n",
    "    \n",
    "    Arguments:\n",
    "    train_x -- training dataset\n",
    "    valid_x  - validation dataset \n",
    "\n",
    "    Return:\n",
    "    xtrain_tfidf  - TF-IDF score on  training dataset\n",
    "    xvalid_tfidf   - TF-IDF score on  validation dataset\n",
    "            \n",
    "    \"\"\"     \n",
    "    \n",
    "    # create a count vectorizer object \n",
    "    count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "    count_vect.fit(data['Job_Title'])\n",
    "    \n",
    "    # transform the training and validation data using count vectorizer object\n",
    "    xtrain_count =  count_vect.transform(train_x['Job_Title'])\n",
    "    xvalid_count =  count_vect.transform(valid_x['Job_Title'])\n",
    "    return xtrain_count,xvalid_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "def word_leve_tf_idf(train_x,valid_x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function will calculate TF-IDF scores of every term in different documnets \n",
    "    \n",
    "    Arguments:\n",
    "    train_x -- training dataset\n",
    "    valid_x  - validation dataset\n",
    "   \n",
    "    Return:\n",
    "    xtrain_tfidf  - TF-IDF score on  training dataset\n",
    "    xvalid_tfidf   - TF-IDF score on  validation dataset\n",
    "            \n",
    "    \"\"\"\n",
    "    tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "    tfidf_vect.fit(data['Job_Title'])\n",
    "    xtrain_tfidf =  tfidf_vect.transform(train_x['Job_Title'])\n",
    "    xvalid_tfidf =  tfidf_vect.transform(valid_x['Job_Title'])\n",
    "    return xtrain_tfidf,xvalid_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ngram level tf-idf \n",
    "def ngrm_level_tf_idf(train_x,valid_x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function will calculate TF-IDF scores of N_gram which are combination of n terms together \n",
    "    \n",
    "    Arguments:\n",
    "    train_x -- training dataset\n",
    "    valid_x  - validation dataset\n",
    "\n",
    "    Return:\n",
    "    xtrain_tfidf_ngram  - TF-IDF score on  training dataset\n",
    "    xvalid_tfidf_ngram   - TF-IDF score on  validation dataset\n",
    "            \n",
    "    \"\"\"\n",
    "    tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "    tfidf_vect_ngram.fit(data['Job_Title'])\n",
    "    xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x['Job_Title'])\n",
    "    xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x['Job_Title'])\n",
    "    return xtrain_tfidf_ngram,xvalid_tfidf_ngram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# characters level tf-idf\n",
    "def char_level_tf_idf(train_x,valid_x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function will calculate TF-IDF scores of character level n_gram \n",
    "    \n",
    "    Arguments:\n",
    "    train_x -- training dataset\n",
    "    valid_x  - validation dataset\n",
    "   \n",
    "    Return:\n",
    "    xtrain_tfidf  - TF-IDF score on  training dataset\n",
    "    xvalid_tfidf   - TF-IDF score on  validation dataset\n",
    "            \n",
    "    \"\"\"\n",
    "        \n",
    "    tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "    tfidf_vect_ngram_chars.fit(data['Job_Title'])\n",
    "    xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x['Job_Title']) \n",
    "    xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x['Job_Title']) \n",
    "    return xtrain_tfidf_ngram_chars,xvalid_tfidf_ngram_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    \"\"\"\n",
    "    Function will fit the training dataset on the classifier\n",
    "    \n",
    "    Arguments:\n",
    "    classifier -- type of model to be used\n",
    "    feature_vector_train  -- training data \n",
    "    label  -- dependent variable of training \n",
    "    feature_vector_valid  -- validation data set\n",
    "    \n",
    "    Return:\n",
    "    np.mean(precision) --  mean of precision of all 3 classes ( Precision = TP/Predicted Positive )\n",
    "    np.mean(recall)  --  mean of recall of all 3 classes   ( Recall = TP/Actual Positive )\n",
    "    np.mean(fscore)  --  mean of fscore of all 3 classes\n",
    "    accuracy   --  mean of accuracy of all 3 classes\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    # creating empty list for storing values\n",
    "    precision = []\n",
    "    recall = []\n",
    "    fscore = []\n",
    "    accuracy = 0\n",
    "    \n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "            \n",
    "    p,r,f,s = precision_recall_fscore_support(predictions, valid_y, average='weighted')\n",
    "    accuracy  = metrics.accuracy_score(predictions, valid_y)\n",
    "    precision.append(p)\n",
    "    recall.append(r)\n",
    "    fscore.append(f)\n",
    "    return np.mean(precision),np.mean(recall),np.mean(fscore),np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "data  = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modifying data for removing null value \n",
    "\n",
    "data = data_modification(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the respective column in separate series for ease of use \n",
    "\n",
    "titles = data['Job_Title']\n",
    "labels = data['Category']\n",
    "dclass = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessig the titles\n",
    "\n",
    "data['Job_Title'] = preProcessing(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since this is imbalanced class classification problem so we will take only those categories which has atleast 2 values \n",
    "\n",
    "data['cnt'] = data.groupby(['Category'])['Job_Title'].transform('count')\n",
    "data = data.drop(data[data.cnt==1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the data \n",
    "\n",
    "train_x, valid_x, train_y, valid_y=       split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating count vector of terms in Job_Title\n",
    "\n",
    "xtrain_count,xvalid_count = create_countvector(train_x,valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating word level Tf-tdf matrix\n",
    "\n",
    "xtrain_tfidf,xvalid_tfidf =      word_leve_tf_idf(train_x,valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating n_gram level Tf-tdf matrix\n",
    "\n",
    "xtrain_tfidf_ngram,xvalid_tfidf_ngram = ngrm_level_tf_idf(train_x,valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating char level level Tf-tdf matrix\n",
    "\n",
    "xtrain_tfidf_ngram_chars,xvalid_tfidf_ngram_chars =char_level_tf_idf(train_x,valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe for appaneding different type of validation parameter \n",
    "\n",
    "metrics_NB = pd.DataFrame({\n",
    "                    'Model_Name':['Naive Bayes','Naive Bayes','Naive Bayes','Naive Bayes'],\n",
    "                    'Type_vector':['Count','Word','N-Gram','Char'],\n",
    "                    'Precision':[None,None,None,None],\n",
    "                    'Recall':[None,None,None,None],\n",
    "                    'F-Score':[None,None,None,None],\n",
    "                    'Accuracy':[None,None,None,None]\n",
    "                   \n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prachi-mudit\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\prachi-mudit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors: precision  0.8104312268659407 recall 0.51935352437865 fscore 0.6003121566352744 accuracy 0.51935352437865\n",
      "NB, WordLevel TF-IDF:: precision  0.8403168512339607 recall 0.49307347548553576 fscore 0.5830813230599864 accuracy 0.49307347548553576\n",
      "NB, N-Gram Vectors:  precision  0.8092676368338143 recall 0.5290642401195165 fscore 0.5874727454642509 accuracy 0.5290642401195165\n",
      "NB, CharLevel Vectors:  precision  0.816801986122359 recall 0.5103897867716963 fscore 0.5979850480506372 accuracy 0.5103897867716963\n"
     ]
    }
   ],
   "source": [
    "# Naive BAyes Algoorithm :Based in Bayes theorem \n",
    "# Assume independence of predictors \n",
    "\n",
    "# Naive Bayes on Count Vectors\n",
    "precision, recall, fscore, accuracy  = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"NB, Count Vectors: precision \", precision, \"recall\",recall,\"fscore\",fscore,\"accuracy\",accuracy,  )\n",
    "metrics_NB.ix[0,'Precision']= precision \n",
    "metrics_NB.ix[0,'Recall']= recall \n",
    "metrics_NB.ix[0,'F-Score']= fscore \n",
    "metrics_NB.ix[0,'Accuracy']= accuracy \n",
    "\n",
    "\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "precision, recall, fscore, accuracy  = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF:: precision \", precision, \"recall\",recall,\"fscore\",fscore,\"accuracy\",accuracy,  )\n",
    "metrics_NB.ix[1,'Precision']= precision \n",
    "metrics_NB.ix[1,'Recall']= recall \n",
    "metrics_NB.ix[1,'F-Score']= fscore \n",
    "metrics_NB.ix[1,'Accuracy']= accuracy \n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "precision, recall, fscore, accuracy  = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, N-Gram Vectors:  precision \", precision, \"recall\",recall,\"fscore\",fscore,\"accuracy\",accuracy)\n",
    "metrics_NB.ix[2,'Precision']= precision \n",
    "metrics_NB.ix[2,'Recall']= recall \n",
    "metrics_NB.ix[2,'F-Score']= fscore \n",
    "metrics_NB.ix[2,'Accuracy']= accuracy \n",
    "\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "precision, recall, fscore, accuracy  = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, CharLevel Vectors:  precision \", precision, \"recall\",recall,\"fscore\",fscore,\"accuracy\",accuracy)\n",
    "metrics_NB.ix[3,'Precision']= precision \n",
    "metrics_NB.ix[3,'Recall']= recall \n",
    "metrics_NB.ix[3,'F-Score']= fscore \n",
    "metrics_NB.ix[3,'Accuracy']= accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Type_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.519354</td>\n",
       "      <td>0.600312</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.810431</td>\n",
       "      <td>0.519354</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.493073</td>\n",
       "      <td>0.583081</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.840317</td>\n",
       "      <td>0.493073</td>\n",
       "      <td>Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.529064</td>\n",
       "      <td>0.587473</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.809268</td>\n",
       "      <td>0.529064</td>\n",
       "      <td>N-Gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.51039</td>\n",
       "      <td>0.597985</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.816802</td>\n",
       "      <td>0.51039</td>\n",
       "      <td>Char</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy   F-Score   Model_Name Precision    Recall Type_vector\n",
       "0  0.519354  0.600312  Naive Bayes  0.810431  0.519354       Count\n",
       "1  0.493073  0.583081  Naive Bayes  0.840317  0.493073        Word\n",
       "2  0.529064  0.587473  Naive Bayes  0.809268  0.529064      N-Gram\n",
       "3   0.51039  0.597985  Naive Bayes  0.816802   0.51039        Char"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_NB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe for appaneding different type of validation parameter \n",
    "\n",
    "metrics_LR = pd.DataFrame({\n",
    "                    'Model_Name':['Linear Model','Linear Model','Linear Model','Linear Model'],\n",
    "                    'Type_vector':['Count','Word','N-Gram','Char'],\n",
    "                    'Precision':[None,None,None,None],\n",
    "                    'Recall':[None,None,None,None],\n",
    "                    'F-Score':[None,None,None,None],\n",
    "                    'Accuracy':[None,None,None,None]\n",
    "                   \n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prachi-mudit\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\prachi-mudit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors: precision  0.7922052298880102 recall 0.6595137851419258 fscore 0.7014662094373432 accuracy 0.6595137851419258\n",
      "LR, WordLevel TF-IDF:: precision  0.7986293640827916 recall 0.6308569876409073 fscore 0.684223382888476 accuracy 0.6595137851419258\n",
      "LR, N-Gram Vectors:  precision  0.7774708626726773 recall 0.6117071845715062 fscore 0.6463358147894406 accuracy 0.6595137851419258\n",
      "LR, CharLevel Vectors:  precision  0.7985138754451147 recall 0.639413282629363 fscore 0.6945817638390521 accuracy 0.6595137851419258\n"
     ]
    }
   ],
   "source": [
    "# Using Linear CLassifier (Logistic Regression)\n",
    "# It estimates probabilities using a logistic/sigmoid function\n",
    "\n",
    "# # Linear Classifier on Count Vectors\n",
    "precision, recall, fscore, accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"LR, Count Vectors: precision \", precision, \"recall\",recall,\"fscore\",fscore,\"accuracy\",accuracy)\n",
    "\n",
    "metrics_LR.ix[0,'Precision']= precision \n",
    "metrics_LR.ix[0,'Recall']= recall \n",
    "metrics_LR.ix[0,'F-Score']= fscore \n",
    "metrics_LR.ix[0,'Accuracy']= accuracy \n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "precision, recall, fscore, accurac = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"LR, WordLevel TF-IDF:: precision \", precision, \"recall\",recall,\"fscore\",fscore,\"accuracy\",accuracy)\n",
    "metrics_LR.ix[1,'Precision']= precision \n",
    "metrics_LR.ix[1,'Recall']= recall \n",
    "metrics_LR.ix[1,'F-Score']= fscore \n",
    "metrics_LR.ix[1,'Accuracy']= accuracy \n",
    "\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "precision, recall, fscore, accurac = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"LR, N-Gram Vectors:  precision \", precision, \"recall\",recall,\"fscore\",fscore,\"accuracy\",accuracy)\n",
    "metrics_LR.ix[2,'Precision']= precision \n",
    "metrics_LR.ix[2,'Recall']= recall \n",
    "metrics_LR.ix[2,'F-Score']= fscore \n",
    "metrics_LR.ix[2,'Accuracy']= accuracy \n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "precision, recall, fscore, accurac = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"LR, CharLevel Vectors:  precision \", precision, \"recall\",recall,\"fscore\",fscore,\"accuracy\",accuracy)\n",
    "metrics_LR.ix[3,'Precision']= precision \n",
    "metrics_LR.ix[3,'Recall']= recall \n",
    "metrics_LR.ix[3,'F-Score']= fscore \n",
    "metrics_LR.ix[3,'Accuracy']= accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Type_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.659514</td>\n",
       "      <td>0.701466</td>\n",
       "      <td>Linear Model</td>\n",
       "      <td>0.792205</td>\n",
       "      <td>0.659514</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.659514</td>\n",
       "      <td>0.684223</td>\n",
       "      <td>Linear Model</td>\n",
       "      <td>0.798629</td>\n",
       "      <td>0.630857</td>\n",
       "      <td>Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.659514</td>\n",
       "      <td>0.646336</td>\n",
       "      <td>Linear Model</td>\n",
       "      <td>0.777471</td>\n",
       "      <td>0.611707</td>\n",
       "      <td>N-Gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.659514</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>Linear Model</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>Char</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy   F-Score    Model_Name Precision    Recall Type_vector\n",
       "0  0.659514  0.701466  Linear Model  0.792205  0.659514       Count\n",
       "1  0.659514  0.684223  Linear Model  0.798629  0.630857        Word\n",
       "2  0.659514  0.646336  Linear Model  0.777471  0.611707      N-Gram\n",
       "3  0.659514  0.694582  Linear Model  0.798514  0.639413        Char"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_LR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe for appaneding different type of validation parameter \n",
    "\n",
    "metrics_SVM = pd.DataFrame({\n",
    "                    'Model_Name':['SVM'],\n",
    "                    'Type_vector':['Word'],\n",
    "                    'Precision':[None],\n",
    "                    'Recall':[None],\n",
    "                    'F-Score':[None],\n",
    "                    'Accuracy':[None]\n",
    "                   \n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors:  (1.0, 0.051948933858481594, 0.09876702601510555, 0.051948933858481594)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prachi-mudit\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\prachi-mudit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# SVM extractes best possible hyper plane that segregaets 2 classes\n",
    "\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"SVM, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "metrics_SVM.ix[0,'Precision']= precision \n",
    "metrics_SVM.ix[0,'Recall']= recall \n",
    "metrics_SVM.ix[0,'F-Score']= fscore \n",
    "metrics_SVM.ix[0,'Accuracy']= accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Type_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1.0, 0.051948933858481594, 0.0987670260151055...</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>Word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Accuracy   F-Score Model_Name  \\\n",
       "0  (1.0, 0.051948933858481594, 0.0987670260151055...  0.694582        SVM   \n",
       "\n",
       "  Precision    Recall Type_vector  \n",
       "0  0.798514  0.639413        Word  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_SVM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe for appaneding different type of validation parameter \n",
    "\n",
    "metrics_RF = pd.DataFrame({\n",
    "                    'Model_Name':['Random Forest','Random Forest'],\n",
    "                    'Type_vector':['Count','Word'],\n",
    "                    'Precision':[None,None],\n",
    "                    'Recall':[None,None],\n",
    "                    'F-Score':[None,None],\n",
    "                    'Accuracy':[None,None]\n",
    "                   \n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prachi-mudit\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\prachi-mudit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors: precision  0.7985138754451147 recall 0.639413282629363 fscore 0.6945817638390521 accuracy (0.7786192863234669, 0.6862012766535379, 0.7096240415963905, 0.6862012766535379)\n",
      "RF, WordLevel TF-IDF:: precision  0.7985138754451147 recall 0.639413282629363 fscore 0.6945817638390521 accuracy (0.7746231960497377, 0.6896645389107701, 0.7138196738389014, 0.6896645389107701)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prachi-mudit\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Algorithm: Create multiple trees, subsample data and get scores\n",
    "# Using Random forest with all default values \n",
    "\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"RF, Count Vectors: precision \", precision, \"recall\",recall,\"fscore\",fscore,\"accuracy\",accuracy)\n",
    "\n",
    "metrics_RF.ix[0,'Precision']= precision \n",
    "metrics_RF.ix[0,'Recall']= recall \n",
    "metrics_RF.ix[0,'F-Score']= fscore \n",
    "metrics_RF.ix[0,'Accuracy']= accuracy \n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"RF, WordLevel TF-IDF:: precision \", precision, \"recall\",recall,\"fscore\",fscore,\"accuracy\",accuracy)\n",
    "\n",
    "metrics_RF.ix[1,'Precision']= precision \n",
    "metrics_RF.ix[1,'Recall']= recall \n",
    "metrics_RF.ix[1,'F-Score']= fscore \n",
    "metrics_RF.ix[1,'Accuracy']= accuracy \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Type_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.7786192863234669, 0.6862012766535379, 0.709...</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.7746231960497377, 0.6896645389107701, 0.713...</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>Word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Accuracy   F-Score     Model_Name  \\\n",
       "0  (0.7786192863234669, 0.6862012766535379, 0.709...  0.694582  Random Forest   \n",
       "1  (0.7746231960497377, 0.6896645389107701, 0.713...  0.694582  Random Forest   \n",
       "\n",
       "  Precision    Recall Type_vector  \n",
       "0  0.798514  0.639413       Count  \n",
       "1  0.798514  0.639413        Word  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_RF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ALthough we have calculated different metics , a good model should be the one which has good precisiona nd good recall. \n",
    "# This can be effectively measured by F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ValidationScore = metrics_NB.append(metrics_LR,ignore_index = True)\n",
    "ValidationScore = crossValidationScore.append(metrics_SVM,ignore_index = True)\n",
    "ValidationScore = crossValidationScore.append(metrics_RF,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Type_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.519354</td>\n",
       "      <td>0.600312</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.810431</td>\n",
       "      <td>0.519354</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.493073</td>\n",
       "      <td>0.583081</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.840317</td>\n",
       "      <td>0.493073</td>\n",
       "      <td>Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.529064</td>\n",
       "      <td>0.587473</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.809268</td>\n",
       "      <td>0.529064</td>\n",
       "      <td>N-Gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.51039</td>\n",
       "      <td>0.597985</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.816802</td>\n",
       "      <td>0.51039</td>\n",
       "      <td>Char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.659514</td>\n",
       "      <td>0.701466</td>\n",
       "      <td>Linear Model</td>\n",
       "      <td>0.792205</td>\n",
       "      <td>0.659514</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.659514</td>\n",
       "      <td>0.684223</td>\n",
       "      <td>Linear Model</td>\n",
       "      <td>0.798629</td>\n",
       "      <td>0.630857</td>\n",
       "      <td>Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.659514</td>\n",
       "      <td>0.646336</td>\n",
       "      <td>Linear Model</td>\n",
       "      <td>0.777471</td>\n",
       "      <td>0.611707</td>\n",
       "      <td>N-Gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.659514</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>Linear Model</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>Char</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1.0, 0.051948933858481594, 0.0987670260151055...</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.7767306904604047, 0.6864729050658699, 0.711...</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(0.7751563187632245, 0.690071981529268, 0.7140...</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(0.7786192863234669, 0.6862012766535379, 0.709...</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(0.7746231960497377, 0.6896645389107701, 0.713...</td>\n",
       "      <td>0.694582</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>Word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Accuracy   F-Score  \\\n",
       "0                                            0.519354  0.600312   \n",
       "1                                            0.493073  0.583081   \n",
       "2                                            0.529064  0.587473   \n",
       "3                                             0.51039  0.597985   \n",
       "4                                            0.659514  0.701466   \n",
       "5                                            0.659514  0.684223   \n",
       "6                                            0.659514  0.646336   \n",
       "7                                            0.659514  0.694582   \n",
       "8   (1.0, 0.051948933858481594, 0.0987670260151055...  0.694582   \n",
       "9   (0.7767306904604047, 0.6864729050658699, 0.711...  0.694582   \n",
       "10  (0.7751563187632245, 0.690071981529268, 0.7140...  0.694582   \n",
       "11  (0.7786192863234669, 0.6862012766535379, 0.709...  0.694582   \n",
       "12  (0.7746231960497377, 0.6896645389107701, 0.713...  0.694582   \n",
       "\n",
       "       Model_Name Precision    Recall Type_vector  \n",
       "0     Naive Bayes  0.810431  0.519354       Count  \n",
       "1     Naive Bayes  0.840317  0.493073        Word  \n",
       "2     Naive Bayes  0.809268  0.529064      N-Gram  \n",
       "3     Naive Bayes  0.816802   0.51039        Char  \n",
       "4    Linear Model  0.792205  0.659514       Count  \n",
       "5    Linear Model  0.798629  0.630857        Word  \n",
       "6    Linear Model  0.777471  0.611707      N-Gram  \n",
       "7    Linear Model  0.798514  0.639413        Char  \n",
       "8             SVM  0.798514  0.639413        Word  \n",
       "9   Random Forest  0.798514  0.639413       Count  \n",
       "10  Random Forest  0.798514  0.639413        Word  \n",
       "11  Random Forest  0.798514  0.639413       Count  \n",
       "12  Random Forest  0.798514  0.639413        Word  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidationScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a good classification model,it is important to have good accuracy as well as good F Score \n",
    "# SO based on above scores , we can choose Random FOrest for this model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
